{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11254922,
          "sourceType": "datasetVersion",
          "datasetId": 7032548
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download('shusrith/wikipedia-data-bpe')\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "id": "J3bYiTcBq9iX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4812ec-7214-432f-cc3c-5d03a182ed29"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/shusrith/wikipedia-data-bpe?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.65G/2.65G [00:30<00:00, 94.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwDudaubsUj1",
        "outputId": "3b35e876-5153-49ea-b604-478d6908549f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from datasets import load_dataset\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    vocab_size = 50000\n",
        "    seq_length = 128\n",
        "    num_heads = 12\n",
        "    num_layers = 12\n",
        "    embd_dim = 768\n",
        "    batch_size = 32\n",
        "    learning_rate = 6e-4\n",
        "    epochs = 10\n",
        "    eval_interval = 500\n",
        "    eval_iters = 200\n",
        "    warmup_iters = 2000\n",
        "    min_lr = 6e-5\n",
        "    grad_clip = 1.0\n",
        "    weight_decay = 0.1\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.95\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    checkpoint_dir = '.'\n",
        "    dataset_path = f'{path}/train'"
      ],
      "metadata": {
        "trusted": true,
        "id": "xEEMAZD-q9id"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(Config.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FF(nn.Module):\n",
        "    def __init__(self, embd_dim):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(embd_dim, 8 * embd_dim)\n",
        "        self.linear2 = nn.Linear(8 * embd_dim, embd_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.gelu(self.linear1(x)))\n",
        "\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, n_embd, head_size, seq_length):\n",
        "        super().__init__()\n",
        "        self.head_size = head_size\n",
        "        self.key = nn.Linear(n_embd, self.head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, self.head_size, bias=False)\n",
        "        self.values = nn.Linear(n_embd, self.head_size, bias=False)\n",
        "        self.scale_factor = self.head_size**-0.5\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        k = self.key(k)\n",
        "        q = self.query(q)\n",
        "        v = self.values(v)\n",
        "\n",
        "        w = (q @ k.transpose(-2, -1)) * self.scale_factor\n",
        "\n",
        "        mask = torch.tril(torch.ones(self.seq_length, self.seq_length, device=w.device)).unsqueeze(0)\n",
        "        w = w.masked_fill(mask == 0, float('-inf'))\n",
        "        w = nn.functional.softmax(w, dim=-1)\n",
        "        return w @ v\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, embd_dim, seq_length):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [\n",
        "                Head(embd_dim, embd_dim // num_heads, seq_length)\n",
        "                for i in range(num_heads)\n",
        "            ]\n",
        "        )\n",
        "        self.out = nn.Linear(embd_dim, embd_dim)\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        head_out = [head(q, k, v) for head in self.heads]\n",
        "        concat = torch.cat(head_out, dim=-1)\n",
        "        return self.out(concat)\n",
        "\n",
        "class Decode(nn.Module):\n",
        "    def __init__(self, num_heads, embd_dim, seq_length):\n",
        "        super().__init__()\n",
        "        self.attn1 = MultiHeadAttention(num_heads, embd_dim, seq_length)\n",
        "        self.attn2 = MultiHeadAttention(num_heads, embd_dim, seq_length)\n",
        "        self.norm1 = nn.LayerNorm(embd_dim)\n",
        "        self.norm2 = nn.LayerNorm(embd_dim)\n",
        "        self.norm3 = nn.LayerNorm(embd_dim)\n",
        "        self.ff = FF(embd_dim)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        self.dropout3 = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = self.norm1(x)\n",
        "        attn_out = self.attn1(x_norm, x_norm, x_norm)\n",
        "        x = x + self.dropout1(attn_out)\n",
        "        x_norm = self.norm2(x)\n",
        "        attn_out = self.attn2(x_norm, x_norm, x_norm)\n",
        "        x = x + self.dropout2(attn_out)\n",
        "        x_norm = self.norm3(x)\n",
        "        x = x + self.dropout3(self.ff(x_norm))\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        seq_length,\n",
        "        num_layers,\n",
        "        num_heads,\n",
        "        embd_dim,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embd_dim)\n",
        "        self.pos_embedding = nn.Embedding(seq_length, embd_dim)\n",
        "        self.layers = nn.ModuleList(\n",
        "            [Decode(num_heads, embd_dim, seq_length) for i in range(num_layers)]\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(embd_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_length = x.size(1)\n",
        "        positions = (\n",
        "            torch.arange(0, seq_length, device=x.device).unsqueeze(0).expand_as(x)\n",
        "        )\n",
        "        x1 = self.embedding(x) + self.pos_embedding(positions)\n",
        "        for layer in self.layers:\n",
        "            x1 = layer(x1)\n",
        "        return self.norm(x1)\n",
        "\n",
        "class GPT3(nn.Module):\n",
        "    def __init__(self, vocab_size, seq_length, num_heads, num_layers, embd_dim):\n",
        "        super().__init__()\n",
        "        self.dec = Decoder(vocab_size, seq_length, num_heads, num_layers, embd_dim)\n",
        "        self.out = nn.Linear(embd_dim, vocab_size)\n",
        "        self.seq_length = seq_length\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.dec(x)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n",
        "    def generate(self, input_ids, max_length=50, temperature=0.9):\n",
        "        self.eval()\n",
        "        output = input_ids.tolist()[0]\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_length):\n",
        "                input_ids = input_ids.to(\"cuda\")\n",
        "                logits = self(input_ids)\n",
        "                logits = logits[:, -1, :] / temperature\n",
        "                probs = nn.functional.softmax(logits, dim=-1)\n",
        "                next_token = torch.multinomial(probs, num_samples=1)\n",
        "                output.append(int(next_token[0, 0]))\n",
        "                input_ids = torch.cat([input_ids[:, 1:], next_token], dim=1)\n",
        "        self.train()\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "id": "-IFHXef3q9if"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, tokenized_data_path, seq_length):\n",
        "        self.seq_length = seq_length\n",
        "        self.data = []\n",
        "\n",
        "        print(f\"Loading data from {tokenized_data_path}...\")\n",
        "\n",
        "        # Get all .npz files (with more flexible naming)\n",
        "        npz_files = [f for f in os.listdir(tokenized_data_path) if f.endswith('.npz')][:10]\n",
        "        if not npz_files:\n",
        "            raise ValueError(\"No .npz files found in directory\")\n",
        "\n",
        "        # Load files in arbitrary order (removed problematic sorting)\n",
        "        for filename in npz_files:\n",
        "            filepath = os.path.join(tokenized_data_path, filename)\n",
        "            try:\n",
        "                with np.load(filepath) as f:\n",
        "                    arr = f['batch_arrays']\n",
        "                    if len(arr) > 0:\n",
        "                        self.data.append(arr)\n",
        "                    else:\n",
        "                        print(f\"Skipping empty array in {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if not self.data:\n",
        "            raise ValueError(\"No valid data loaded - all files were empty or corrupted\")\n",
        "\n",
        "        # Concatenate all arrays\n",
        "        try:\n",
        "            self.data = np.concatenate(self.data)\n",
        "            print(f\"\\nTotal tokens loaded: {len(self.data):,}\")\n",
        "        except ValueError as e:\n",
        "            raise ValueError(f\"Error concatenating arrays: {e}\")\n",
        "\n",
        "        # Calculate available sequences\n",
        "        self.total_sequences = (len(self.data) - 1) // self.seq_length\n",
        "        if self.total_sequences <= 0:\n",
        "            raise ValueError(\n",
        "                f\"Not enough data for seq_length={seq_length}. \"\n",
        "                f\"Need ≥{seq_length+1} tokens, got {len(self.data)}\"\n",
        "            )\n",
        "        print(f\"Available sequences: {self.total_sequences:,}\\n\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.seq_length\n",
        "        end = start + self.seq_length + 1  # +1 for target\n",
        "\n",
        "        if end > len(self.data):\n",
        "            raise IndexError(f\"Sequence {idx} out of range\")\n",
        "\n",
        "        chunk = self.data[start:end]\n",
        "        return (\n",
        "            torch.tensor(chunk[:-1], dtype=torch.long),  # input\n",
        "            torch.tensor(chunk[1:], dtype=torch.long)   # target\n",
        "        )"
      ],
      "metadata": {
        "trusted": true,
        "id": "R6kN2-OYq9ii"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    f\"{path}/vocab/vocab.json\",\n",
        "    f\"{path}/vocab/merges.txt\"\n",
        ")\n",
        "\n",
        "# Load dataset\n",
        "full_dataset = GPTDataset(Config.dataset_path, Config.seq_length)\n",
        "\n",
        "# Split into train, val, test\n",
        "train_size = int(0.9 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size]\n",
        ")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=Config.batch_size, shuffle=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, batch_size=Config.batch_size, shuffle=False\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "RJZHEU16q9im",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41fb7e3a-bb5e-4cd5-9115-b0d7f38b960c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from /root/.cache/kagglehub/datasets/shusrith/wikipedia-data-bpe/versions/2/train...\n",
            "\n",
            "Total tokens loaded: 163,399,626\n",
            "Available sequences: 1,276,559\n",
            "\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT3(\n",
        "    vocab_size=Config.vocab_size,\n",
        "    seq_length=Config.seq_length,\n",
        "    num_heads=Config.num_heads,\n",
        "    num_layers=Config.num_layers,\n",
        "    embd_dim=Config.embd_dim\n",
        ").to(Config.device)"
      ],
      "metadata": {
        "id": "JR6Rz5lxrSzk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total number of parameters: {total_params:,}\")\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=Config.learning_rate,\n",
        "    weight_decay=Config.weight_decay,\n",
        "    betas=(Config.beta1, Config.beta2)\n",
        ")"
      ],
      "metadata": {
        "id": "DCCY1tYgrUku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ece09064-955e-4c47-bff5-147705d4b805"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 246,975,824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(it):\n",
        "    if it < Config.warmup_iters:\n",
        "        return Config.learning_rate * it / Config.warmup_iters\n",
        "    if it > Config.warmup_iters:\n",
        "        return max(\n",
        "            Config.min_lr,\n",
        "            Config.learning_rate * (0.1 ** ((it - Config.warmup_iters) / (Config.warmup_iters * 10)))\n",
        "        )\n",
        "    decay_ratio = (it - Config.warmup_iters) / (Config.warmup_iters * 9)\n",
        "    assert 0 <= decay_ratio <= 1\n",
        "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))\n",
        "    return Config.min_lr + coeff * (Config.learning_rate - Config.min_lr)"
      ],
      "metadata": {
        "id": "yclgizNArWqx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(batch):\n",
        "    x, y = batch\n",
        "    x, y = x.to(Config.device), y.to(Config.device)\n",
        "\n",
        "    logits = model(x)\n",
        "    B, T, C = logits.shape\n",
        "    logits = logits.view(B*T, C)\n",
        "    y = y.view(B*T)\n",
        "\n",
        "    loss = nn.functional.cross_entropy(logits, y)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    with torch.no_grad():\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        correct = (preds == y).sum().item()\n",
        "        total = y.size(0)\n",
        "        accuracy = correct / total\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "FI3AaQb6rZ70"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_step(batch):\n",
        "    x, y = batch\n",
        "    x, y = x.to(Config.device), y.to(Config.device)\n",
        "\n",
        "    logits = model(x)\n",
        "    B, T, C = logits.shape\n",
        "    logits = logits.view(B * T, C)\n",
        "    y = y.view(B * T)\n",
        "\n",
        "    loss = nn.functional.cross_entropy(logits, y)\n",
        "\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    correct = (preds == y).sum().item()\n",
        "    accuracy = correct / y.size(0)\n",
        "\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "n8WXPKBYAfBv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "\n",
        "    pbar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "    for batch in pbar:\n",
        "        loss, accuracy = eval_step(batch)\n",
        "        losses.append(loss.item())\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'loss': f\"{loss.item():.4f}\",\n",
        "            'accuracy': f\"{accuracy:.4f}\"\n",
        "        })\n",
        "\n",
        "    return np.mean(losses), np.mean(accuracies)"
      ],
      "metadata": {
        "id": "CFJ-I894rdLN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    best_val_loss = float('inf')\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    # Convert config to a serializable dictionary\n",
        "    config_dict = {\n",
        "        k: v for k, v in vars(Config).items()\n",
        "        if not k.startswith('__') and not callable(v)\n",
        "    }\n",
        "\n",
        "    for epoch in range(Config.epochs):\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{Config.epochs}\")\n",
        "\n",
        "        for it, batch in enumerate(pbar):\n",
        "            lr = get_lr(it + epoch * len(train_loader))\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "            loss, accuracy = train_step(batch)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), Config.grad_clip)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': loss.item(),\n",
        "                'accuracy': accuracy,\n",
        "                'lr': lr\n",
        "            })\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            train_accuracies.append(accuracy)\n",
        "\n",
        "            if it+ 1 % Config.eval_interval == 0 or it == len(train_loader) - 1:\n",
        "                val_loss, val_accuracy = evaluate()\n",
        "                val_losses.append(val_loss)\n",
        "                val_accuracies.append(val_accuracy)\n",
        "\n",
        "                print(f\"\\nStep {it}:\")\n",
        "                print(f\"Train Loss: {loss.item():.4f} | Train Acc: {accuracy:.4f}\")\n",
        "                print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    checkpoint = {\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'epoch': epoch,\n",
        "                        'best_val_loss': best_val_loss,\n",
        "                        'config': config_dict,\n",
        "                    }\n",
        "                    torch.save(\n",
        "                        checkpoint,\n",
        "                        os.path.join(Config.checkpoint_dir, 'best_model.pth'),\n",
        "                        pickle_protocol=4\n",
        "                    )\n",
        "                    print(\"Model saved!\")\n",
        "\n",
        "                model.train()\n",
        "\n",
        "        epoch_checkpoint = {\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'best_val_loss': best_val_loss,\n",
        "            'config': config_dict,\n",
        "        }\n",
        "        torch.save(\n",
        "            epoch_checkpoint,\n",
        "            os.path.join(Config.checkpoint_dir, f'epoch_{epoch}.pth'),\n",
        "            pickle_protocol=4\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, train_accuracies, val_accuracies"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T17:40:57.273372Z",
          "iopub.execute_input": "2025-04-03T17:40:57.273681Z",
          "iopub.status.idle": "2025-04-03T17:41:01.47096Z",
          "shell.execute_reply.started": "2025-04-03T17:40:57.273659Z",
          "shell.execute_reply": "2025-04-03T17:41:01.469821Z"
        },
        "id": "8ouz9BzOq9io"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, train_accuracies, val_accuracies = train()\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(Config.checkpoint_dir, 'final_model.pth'))"
      ],
      "metadata": {
        "id": "X9P6wuc5rfUY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "ddcc5f4a-0eb4-423e-ce99-fd241f967948"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10:   0%|          | 114/35904 [03:48<19:54:59,  2.00s/it, loss=8.46, accuracy=0.092, lr=3.39e-5]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-afb6c6c29161>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-8383c99100d9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_clip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Train')\n",
        "plt.plot(np.linspace(0, len(train_losses), len(val_losses)), val_losses, label='Validation')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, label='Train')\n",
        "plt.plot(np.linspace(0, len(train_accuracies), len(val_accuracies)), val_accuracies, label='Validation')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(os.path.join(Config.checkpoint_dir, 'training_curves.png'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w9dQskgnrg3x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}